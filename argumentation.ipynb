{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b4a1a-42bf-43b9-861a-49edc01afd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_community.llms import Ollama\n",
    "import sqlalchemy as sal\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine import URL\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import stanza\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ad7c1-b58b-4392-b72e-06d39354f1ab",
   "metadata": {},
   "source": [
    "# Creation of PERSUADE corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1ba9d-db4a-45fc-bcd3-091dd6426f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/scrosseye/persuade_corpus_2.0\n",
    "df = pd.read_csv('persuade_2.0_human_scores_demo_id_github.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69256d-0a6e-4c91-a430-344cae2995ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df\n",
    "df_filtered = df_filtered[df_filtered['prompt_name'] != 'Exploring Venus']\n",
    "df_filtered = df_filtered[df_filtered['prompt_name'] != 'Facial action coding system']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8925a15-7356-4c42-b38c-9316b84563b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be754d1-b177-4155-b849-d76480dd132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['prompt_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d651d1-747a-4b7e-ab1f-35da4f61c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['assignment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e3a82-d263-4f69-9f9e-6f2d1856820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered[df_filtered['holistic_essay_score'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d3b0c-9926-4b6c-b330-564d8095b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['word_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc65143c-05c7-4ffe-afef-423f46c60c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.DataFrame()\n",
    "for p in df_filtered['prompt_name'].unique():\n",
    "    df_sample = pd.concat([df_sample, df_filtered[df_filtered['prompt_name'] == p].sample(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25a526-a65f-4b8b-ac8f-3deaae35b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_sample.iterrows():\n",
    "    file_name = row[\"essay_id_comp\"] + '_' + row[\"prompt_name\"].replace(\"\\\"\", \"\").replace(\"?\", \"\") + '.txt'\n",
    "    with open(file_name, \"w\", encoding='utf-8') as f:\n",
    "        f.write(row[\"full_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7fc55-01b9-43f2-b7bb-e5bfab0f35e3",
   "metadata": {},
   "source": [
    "# Creation of LLM corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02243236-a195-450e-a8b9-5974de4308f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d492d4-c519-402e-94a0-f89a10908e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.getcwd() + \"/prompts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9961dab6-af1b-455b-a508-debf56b0ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for file in os.listdir(input_dir):\n",
    "    input_file = os.path.join(input_dir, file)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(input_file):\n",
    "        topic = file[ : -4]\n",
    "        print(topic)\n",
    "        with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            topic = [topic, text]\n",
    "            topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf93b69c-8331-4305-980c-afd1ef465fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topics[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50580ebc-85fa-4530-98f2-8f040f3f1881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = text.replace(\"*\",\"\").replace(\"#\",\"\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488f6882-1221-451d-8478-b93427fe07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_llm(llm, name):\n",
    "    \n",
    "    for topic in topics:   \n",
    "        \n",
    "        file_name = name + \"_\" + topic[0] + \".txt\"\n",
    "        print(file_name)\n",
    "       \n",
    "        prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "            Your task is to write an argumentative essay on the following topic. Your aim is to persuade the reader. \n",
    "            You utilize critical thinking and logical reasoning in your argument to ensure discourse coherence and cohesion. \n",
    "            You make extensive use of complex, compound sentences. You do NOT use lists or bullet points.\n",
    "            Topic: {topic}\n",
    "        \"\"\")\n",
    "    \n",
    "        output_parser = StrOutputParser()    \n",
    "        \n",
    "        chain = prompt | llm | output_parser\n",
    "        \n",
    "        answer = chain.invoke({\"topic\": topic[1]})   \n",
    "\n",
    "        answer = clean_text(answer)\n",
    "        \n",
    "        with open(file_name, \"w\", encoding='utf-8') as f:\n",
    "            f.write(answer)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9efcac6-beb0-468b-83ec-d2a91153f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHATGPT API\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-4\",\n",
    "    temperature = temperature,\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "invoke_llm(llm, \"ChatGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea89bce-bbc8-4458-8f13-64e366651247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMINI API\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model = \"gemini-1.5-pro-latest\",\n",
    "    temperature = temperature,\n",
    "    google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    ")\n",
    "invoke_llm(llm, \"Gemini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ab307-ebb0-485e-8075-ed8453ef0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMMA OLLAMA COLAB\n",
    "llm = Ollama(\n",
    "    base_url = \"https://ab9f-34-83-144-154.ngrok-free.app\", \n",
    "    model=\"gemma2\",\n",
    "    temperature = temperature\n",
    ")\n",
    "invoke_llm(llm, \"Gemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc2b71-991a-487d-bd89-3aa9f79a63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MISTRAL API\n",
    "llm = ChatMistralAI(\n",
    "    model = \"mistral-large-latest\",\n",
    "    temperature = temperature,\n",
    "    api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    ")\n",
    "invoke_llm(llm, \"Mistral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a44b150-74bb-41ac-bb90-1077696b0111",
   "metadata": {},
   "source": [
    "# Search for linking adverbials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37329a35-21b7-4c9f-8825-c95964f51acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_url = URL.create(\n",
    "    \"mssql+pyodbc\",\n",
    "    host=\".\",\n",
    "    port=1433,\n",
    "    database=\"argumentation\",\n",
    "    query={\n",
    "        \"driver\": \"ODBC Driver 18 for SQL Server\",\n",
    "        \"Encrypt\": \"yes\",\n",
    "        \"TrustServerCertificate\": \"yes\",\n",
    "        \"TrustedConnection\": \"yes\"\n",
    "    },\n",
    ")\n",
    "engine = create_engine(connection_url)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521b74a-3bda-42ef-bd53-4ca7ee953e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM dbo.MARKERS'\n",
    "df = pd.read_sql(query, engine, index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebb074-a91d-47da-8468-971b2ed39aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['theory'] == 'Biber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf904066-b748-47ad-a68e-7f90d39f42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['marker_id', 'valid', 'author', 'file', 'construction_type', 'start_pos', 'end_pos', 'left_context', 'match', 'right_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f70296f-2ead-490e-989d-b6f30c843ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_adverbials(input_dir):\n",
    "    \n",
    "    df_match = pd.DataFrame(columns = columns)\n",
    "    for file in os.listdir(input_dir):\n",
    "        input_file = os.path.join(input_dir, file)\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(input_file):\n",
    "            with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "                if file.startswith(tuple(['ChatGPT','Claude','Gemini','Gemma','Llama','Mistral'])):\n",
    "                    author = 'LLM'\n",
    "                else:\n",
    "                    author = 'Student'\n",
    "    \n",
    "                text = f.read()\n",
    "                text = text.replace(\"\\n\", \" \")\n",
    "                for index, row in df.iterrows():\n",
    "                    marker = row['search_marker']\n",
    "                    if marker.strip() not in ['!', '?'] :\n",
    "                        marker = row['search_marker']\n",
    "                        pattern = r\"\\b(\" + re.escape(marker)  + r\")\\b\"\n",
    "                        # Find all occurences\n",
    "                        matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "                        for m in matches:\n",
    "                            start_pos = m.start() - 250\n",
    "                            if start_pos < 0:\n",
    "                                start_pos = 0\n",
    "                            end_pos =  m.end();\n",
    "                            df_m = pd.DataFrame.from_dict([{\n",
    "                                'marker_id' : index, \n",
    "                                'valid' : 0,\n",
    "                                'author' : author,\n",
    "                                'file' : file,\n",
    "                                'construction_type' : row['construction_type'],                                \n",
    "                                'start_pos' : m.start(), \n",
    "                                'end_pos' : m.end(), \n",
    "                                'left_context' : text[start_pos : m.start()], \n",
    "                                'match' : m.group(),\n",
    "                                'right_context' : text[m.end() : m.end() + 250]\n",
    "                            }])\n",
    "    \n",
    "                            df_match = pd.concat([df_match, df_m], ignore_index=True)\n",
    "                            \n",
    "    return df_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3dff1d-731f-4d95-a3a8-1265dc3d637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.getcwd() + \"/LLM\"\n",
    "df_match_llm = search_for_adverbials(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78655f6-416a-4092-b450-d1a5beb14af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.getcwd() + \"/Students\"\n",
    "df_match_stu = search_for_adverbials(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e043cd24-c4f5-4bc8-b34e-200093b92146",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_match_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ccdc6e-3743-412f-a17e-d71a4ffbad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_match_stu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6a1ce-1d04-4a39-b43c-3f3089f73f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match = pd.concat([df_match_llm, df_match_stu], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd913f-1c9f-4a09-9990-609140d9e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match.to_excel(\"linking_adverbials.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b636c23b-f7cc-48ac-887c-9ff6b0496f51",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0de10-7cdc-432d-9436-8e17a40a0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_files(input_dir, output_csv):\n",
    "\n",
    "    nlp = stanza.Pipeline('en', download_method=None)\n",
    "    columns = ['file_id', 'sent_id','id','text','lemma','upos','xpos','feats','head','deprel','start_char','end_char','ner','multi_ner', 'misc']\n",
    "    parse_df = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    for file in os.listdir(input_dir):        \n",
    "        input_file = os.path.join(input_dir, file)   \n",
    "        print(input_file)\n",
    "        if os.path.isfile(input_file):\n",
    "            with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "                file_df = pd.DataFrame(columns = columns)            \n",
    "                text = f.read()         \n",
    "                doc = nlp(text)\n",
    "                dicts = doc.to_dict()\n",
    "                for i, d in enumerate(dicts):\n",
    "                    df = pd.DataFrame.from_dict(d)\n",
    "                    df['file_id'] = file\n",
    "                    df['sent_id'] = i\n",
    "                    file_df = pd.concat([file_df,df])\n",
    "                \n",
    "                parse_df = pd.concat([parse_df, file_df])\n",
    "                parse_df.to_csv(output_csv, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d05f295-3939-43c4-a22f-55ca824a0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.getcwd() + \"/LLM\"\n",
    "parse_files(input_dir, \"parsed_llm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b9b52-5052-4cdf-a23b-519485f03fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.getcwd() + \"/Students\"\n",
    "parse_files(input_dir, \"parsed_student.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
